{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio google-generativeai PyPDF2 langchain langchain-community langchain-chroma sentence-transformers -q\n",
        "\n"
      ],
      "metadata": {
        "id": "P58tvOtG0zL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  📘 DocuLingo\n",
        "# İngilizce PDF dosyalarını Türkçe veya İngilizce özetleyen RAG tabanlı chatbot\n",
        "# ============================================================\n",
        "\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import tempfile, os\n",
        "\n",
        "# ==============================\n",
        "# 🔑 API Anahtarını Al\n",
        "# ==============================\n",
        "GOOGLE_API_KEY = input(\"🔑 Gemini API Key'inizi girin: \").strip()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# ==============================\n",
        "# 🧠 Yardımcı Fonksiyonlar\n",
        "# ==============================\n",
        "\n",
        "def summarize_pdf(pdf_file, lang):\n",
        "    \"\"\"PDF dosya yolunu alır, özet çıkarır.\"\"\"\n",
        "    pdf_path = pdf_file  # artık doğrudan path geliyor, read() yok\n",
        "\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            text += content + \"\\n\"\n",
        "\n",
        "\n",
        "    # PDF içeriğini çıkar\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            text += content + \"\\n\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\", generation_config={\"temperature\": 0.3, \"max_output_tokens\": 1500})\n",
        "\n",
        "    if lang == \"Türkçe\":\n",
        "        prompt = f\"\"\"\n",
        "        Aşağıdaki akademik makaleyi Türkçe olarak özetle.\n",
        "        Çalışmanın amacı, yöntemleri, bulguları ve sonuçlarını açıkla.\n",
        "        En az 6-7 cümlelik detaylı bir özet yaz.\n",
        "        Makale:\n",
        "        {text[:7000]}\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Summarize the following academic paper in English.\n",
        "        Explain the goal, methods, findings, and conclusions in detail (6–7 sentences).\n",
        "        Paper:\n",
        "        {text[:7000]}\n",
        "        \"\"\"\n",
        "\n",
        "    summary = model.generate_content(prompt)\n",
        "    summary = getattr(summary, \"text\", str(summary))\n",
        "\n",
        "    # Chroma veritabanı oluştur (RAG için)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
        "    chunks = splitter.split_text(text)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = Chroma.from_texts(chunks, embeddings, persist_directory=\"chroma_db\")\n",
        "\n",
        "    return summary, vectorstore\n",
        "\n",
        "\n",
        "def chat_with_paper(question, vectorstore, lang):\n",
        "    \"\"\"Kullanıcının sorusuna makale tabanlı yanıt ver\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        google_api_key=GOOGLE_API_KEY,\n",
        "        temperature=0.2,\n",
        "        system_prompt=\"You are an academic assistant that only answers based on the provided paper content.\"\n",
        "    )\n",
        "\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        return_source_documents=False\n",
        "    )\n",
        "\n",
        "    result = qa.invoke({\"question\": question, \"chat_history\": []})\n",
        "    return result[\"answer\"]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 🧩 Gradio Arayüzü\n",
        "# ==============================\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## 📘 DocuLingo\")\n",
        "    gr.Markdown(\"**Yapay zekâ destekli özet ve soru-cevap aracı.** Türkçe veya İngilizce olarak makale özetleyebilir ve sorularınızı yanıtlayabilir.\")\n",
        "\n",
        "    lang_choice = gr.Radio([\"Türkçe\", \"İngilizce\"], label=\"🌍 Özet Dili Seçin\")\n",
        "    pdf_input = gr.File(label=\"📂 PDF Dosyası Yükle\", file_types=[\".pdf\"], type=\"filepath\")\n",
        "    summarize_btn = gr.Button(\"🧠 Özeti Oluştur\")\n",
        "\n",
        "    summary_output = gr.Textbox(label=\"📄 Özet\", lines=10)\n",
        "    chat_input = gr.Textbox(label=\"❓ Sorunuzu Yazın\")\n",
        "    chat_btn = gr.Button(\"💬 Sor\")\n",
        "    chat_output = gr.Textbox(label=\"🤖 Cevap\", lines=8)\n",
        "\n",
        "    state_vectorstore = gr.State()\n",
        "\n",
        "    def process_and_summarize(pdf_file, lang):\n",
        "        summary, vectorstore = summarize_pdf(pdf_file, lang)\n",
        "        return summary, vectorstore\n",
        "\n",
        "    summarize_btn.click(\n",
        "        process_and_summarize,\n",
        "        inputs=[pdf_input, lang_choice],\n",
        "        outputs=[summary_output, state_vectorstore]\n",
        "    )\n",
        "\n",
        "    chat_btn.click(\n",
        "        chat_with_paper,\n",
        "        inputs=[chat_input, state_vectorstore, lang_choice],\n",
        "        outputs=chat_output\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "BoomeRLJ04Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DocuLingo (arayüzsüz)\n",
        "# ============================================================\n",
        "\n",
        "!pip install google-generativeai PyPDF2 langchain langchain-community langchain-google-genai chromadb python-dotenv -q\n",
        "!pip install sentence-transformers -q\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from google.colab import files, output\n",
        "from IPython.display import display, HTML\n",
        "import time, os\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 🔑 Gemini API Key\n",
        "# ============================================================\n",
        "GOOGLE_API_KEY = input(\"🔑 Gemini API Key'inizi girin: \").strip()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# ============================================================\n",
        "# 📂 PDF Yükleme\n",
        "# ============================================================\n",
        "print(\"\\n📁 Lütfen özetlenecek PDF dosyasını yükleyin:\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# PDF metnini oku\n",
        "reader = PdfReader(pdf_path)\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content + \"\\n\"\n",
        "\n",
        "# ============================================================\n",
        "# 🌍 Dil Seçimi (Kullanıcıdan Buton ile)\n",
        "# ============================================================\n",
        "print(\"📘 Özet hangi dilde olsun?\")\n",
        "print(\"1️⃣ Türkçe\\n2️⃣ İngilizce\")\n",
        "\n",
        "choice = input(\"Seçiminizi yapın (1 veya 2): \").strip()\n",
        "if choice == \"1\":\n",
        "    chosen_lang = \"tr\"\n",
        "elif choice == \"2\":\n",
        "    chosen_lang = \"en\"\n",
        "else:\n",
        "    print(\"❌ Geçersiz seçim, varsayılan Türkçe seçildi.\")\n",
        "    chosen_lang = \"tr\"\n",
        "\n",
        "print(f\"🔤 Seçilen dil: {chosen_lang}\")\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ✨ Özet Oluşturma (Gemini)\n",
        "# ============================================================\n",
        "model_name = \"gemini-2.0-flash\"\n",
        "model = genai.GenerativeModel(model_name, generation_config={\"temperature\": 0.3, \"max_output_tokens\": 1500})\n",
        "\n",
        "if chosen_lang == \"tr\":\n",
        "   prompt = f\"\"\"\n",
        "    Aşağıdaki akademik makalenin ayrıntılı bir özetini oluştur.\n",
        "    Çalışmanın amacı, kullanılan yöntemler, veriler, bulgular ve sonuçları açıklayan\n",
        "    en az 6-8 cümlelik akademik bir paragraf yaz.\n",
        "    Ayrıca kullanılan modelleri veya algoritmaları da belirt.\n",
        "    Türkçe yaz.\n",
        "\n",
        "    Makale metni:\n",
        "    {text[:7000]}\n",
        "    \"\"\"\n",
        "else:\n",
        "   prompt = f\"\"\"\n",
        "    Provide a detailed summary of the following academic paper.\n",
        "    Include the research goal, methodology, data used, findings, and conclusions.\n",
        "    Write an academic-style paragraph with at least 6–8 sentences.\n",
        "    Also mention any models or algorithms used.\n",
        "    Write in English.\n",
        "\n",
        "    Paper text:\n",
        "    {text[:7000]}\n",
        "    \"\"\"\n",
        "\n",
        "print(\"\\n🤖 Özeti oluşturuyor, lütfen bekleyin...\")\n",
        "summary = model.generate_content(prompt)\n",
        "try:\n",
        "    summary = summary.text\n",
        "except:\n",
        "    summary = str(summary)\n",
        "\n",
        "print(\"\\n📄 ÖZET:\")\n",
        "print(\"────────────────────────────────────────────\")\n",
        "print(summary)\n",
        "print(\"────────────────────────────────────────────\")\n",
        "\n",
        "# ============================================================\n",
        "# 🧩 ChromaDB + Soru Cevap\n",
        "# ============================================================\n",
        "print(\"\\n🔍 Makale içeriği dizine ekleniyor...\")\n",
        "CHROMA_DIR = \"chroma_db\"\n",
        "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "embedding_model = \"models/embedding-001\"\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# HuggingFace ücretsiz embedding modeli\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = Chroma.from_texts(chunks, embeddings, persist_directory=CHROMA_DIR)\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_name,\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0.2,\n",
        "    system_prompt=\"You are an AI academic assistant. Only answer based on the provided paper content.\"\n",
        ")\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "\n",
        "print(\"\\n💬 Artık makaleyle ilgili sorular sorabilirsiniz!\")\n",
        "print(\"Çıkmak için 'q' yazın.\\n\")\n",
        "\n",
        "while True:\n",
        "    question = input(\"❓ Soru: \")\n",
        "    if question.lower() == \"q\":\n",
        "        print(\"🔚 Sohbet sonlandırıldı.\")\n",
        "        break\n",
        "    result = qa.invoke({\"question\": question, \"chat_history\": []})\n",
        "    print(\"\\n🧠 Cevap:\\n\", result[\"answer\"])\n",
        "    print(\"────────────────────────────────────────────\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IJ639tFEhy1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}