{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio google-generativeai PyPDF2 langchain langchain-community langchain-chroma sentence-transformers -q\n",
        "\n"
      ],
      "metadata": {
        "id": "P58tvOtG0zL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  ğŸ“˜ DocuLingo\n",
        "# Ä°ngilizce PDF dosyalarÄ±nÄ± TÃ¼rkÃ§e veya Ä°ngilizce Ã¶zetleyen RAG tabanlÄ± chatbot\n",
        "# ============================================================\n",
        "\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import tempfile, os\n",
        "\n",
        "# ==============================\n",
        "# ğŸ”‘ API AnahtarÄ±nÄ± Al\n",
        "# ==============================\n",
        "GOOGLE_API_KEY = input(\"ğŸ”‘ Gemini API Key'inizi girin: \").strip()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§  YardÄ±mcÄ± Fonksiyonlar\n",
        "# ==============================\n",
        "\n",
        "def summarize_pdf(pdf_file, lang):\n",
        "    \"\"\"PDF dosya yolunu alÄ±r, Ã¶zet Ã§Ä±karÄ±r.\"\"\"\n",
        "    pdf_path = pdf_file  # artÄ±k doÄŸrudan path geliyor, read() yok\n",
        "\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            text += content + \"\\n\"\n",
        "\n",
        "\n",
        "    # PDF iÃ§eriÄŸini Ã§Ä±kar\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        content = page.extract_text()\n",
        "        if content:\n",
        "            text += content + \"\\n\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\", generation_config={\"temperature\": 0.3, \"max_output_tokens\": 1500})\n",
        "\n",
        "    if lang == \"TÃ¼rkÃ§e\":\n",
        "        prompt = f\"\"\"\n",
        "        AÅŸaÄŸÄ±daki akademik makaleyi TÃ¼rkÃ§e olarak Ã¶zetle.\n",
        "        Ã‡alÄ±ÅŸmanÄ±n amacÄ±, yÃ¶ntemleri, bulgularÄ± ve sonuÃ§larÄ±nÄ± aÃ§Ä±kla.\n",
        "        En az 6-7 cÃ¼mlelik detaylÄ± bir Ã¶zet yaz.\n",
        "        Makale:\n",
        "        {text[:7000]}\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Summarize the following academic paper in English.\n",
        "        Explain the goal, methods, findings, and conclusions in detail (6â€“7 sentences).\n",
        "        Paper:\n",
        "        {text[:7000]}\n",
        "        \"\"\"\n",
        "\n",
        "    summary = model.generate_content(prompt)\n",
        "    summary = getattr(summary, \"text\", str(summary))\n",
        "\n",
        "    # Chroma veritabanÄ± oluÅŸtur (RAG iÃ§in)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
        "    chunks = splitter.split_text(text)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = Chroma.from_texts(chunks, embeddings, persist_directory=\"chroma_db\")\n",
        "\n",
        "    return summary, vectorstore\n",
        "\n",
        "\n",
        "def chat_with_paper(question, vectorstore, lang):\n",
        "    \"\"\"KullanÄ±cÄ±nÄ±n sorusuna makale tabanlÄ± yanÄ±t ver\"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        google_api_key=GOOGLE_API_KEY,\n",
        "        temperature=0.2,\n",
        "        system_prompt=\"You are an academic assistant that only answers based on the provided paper content.\"\n",
        "    )\n",
        "\n",
        "    qa = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        return_source_documents=False\n",
        "    )\n",
        "\n",
        "    result = qa.invoke({\"question\": question, \"chat_history\": []})\n",
        "    return result[\"answer\"]\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§© Gradio ArayÃ¼zÃ¼\n",
        "# ==============================\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"## ğŸ“˜ DocuLingo\")\n",
        "    gr.Markdown(\"**Yapay zekÃ¢ destekli Ã¶zet ve soru-cevap aracÄ±.** TÃ¼rkÃ§e veya Ä°ngilizce olarak makale Ã¶zetleyebilir ve sorularÄ±nÄ±zÄ± yanÄ±tlayabilir.\")\n",
        "\n",
        "    lang_choice = gr.Radio([\"TÃ¼rkÃ§e\", \"Ä°ngilizce\"], label=\"ğŸŒ Ã–zet Dili SeÃ§in\")\n",
        "    pdf_input = gr.File(label=\"ğŸ“‚ PDF DosyasÄ± YÃ¼kle\", file_types=[\".pdf\"], type=\"filepath\")\n",
        "    summarize_btn = gr.Button(\"ğŸ§  Ã–zeti OluÅŸtur\")\n",
        "\n",
        "    summary_output = gr.Textbox(label=\"ğŸ“„ Ã–zet\", lines=10)\n",
        "    chat_input = gr.Textbox(label=\"â“ Sorunuzu YazÄ±n\")\n",
        "    chat_btn = gr.Button(\"ğŸ’¬ Sor\")\n",
        "    chat_output = gr.Textbox(label=\"ğŸ¤– Cevap\", lines=8)\n",
        "\n",
        "    state_vectorstore = gr.State()\n",
        "\n",
        "    def process_and_summarize(pdf_file, lang):\n",
        "        summary, vectorstore = summarize_pdf(pdf_file, lang)\n",
        "        return summary, vectorstore\n",
        "\n",
        "    summarize_btn.click(\n",
        "        process_and_summarize,\n",
        "        inputs=[pdf_input, lang_choice],\n",
        "        outputs=[summary_output, state_vectorstore]\n",
        "    )\n",
        "\n",
        "    chat_btn.click(\n",
        "        chat_with_paper,\n",
        "        inputs=[chat_input, state_vectorstore, lang_choice],\n",
        "        outputs=chat_output\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "BoomeRLJ04Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DocuLingo (arayÃ¼zsÃ¼z)\n",
        "# ============================================================\n",
        "\n",
        "!pip install google-generativeai PyPDF2 langchain langchain-community langchain-google-genai chromadb python-dotenv -q\n",
        "!pip install sentence-transformers -q\n",
        "\n",
        "import google.generativeai as genai\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from google.colab import files, output\n",
        "from IPython.display import display, HTML\n",
        "import time, os\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ”‘ Gemini API Key\n",
        "# ============================================================\n",
        "GOOGLE_API_KEY = input(\"ğŸ”‘ Gemini API Key'inizi girin: \").strip()\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“‚ PDF YÃ¼kleme\n",
        "# ============================================================\n",
        "print(\"\\nğŸ“ LÃ¼tfen Ã¶zetlenecek PDF dosyasÄ±nÄ± yÃ¼kleyin:\")\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# PDF metnini oku\n",
        "reader = PdfReader(pdf_path)\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content + \"\\n\"\n",
        "\n",
        "# ============================================================\n",
        "# ğŸŒ Dil SeÃ§imi (KullanÄ±cÄ±dan Buton ile)\n",
        "# ============================================================\n",
        "print(\"ğŸ“˜ Ã–zet hangi dilde olsun?\")\n",
        "print(\"1ï¸âƒ£ TÃ¼rkÃ§e\\n2ï¸âƒ£ Ä°ngilizce\")\n",
        "\n",
        "choice = input(\"SeÃ§iminizi yapÄ±n (1 veya 2): \").strip()\n",
        "if choice == \"1\":\n",
        "    chosen_lang = \"tr\"\n",
        "elif choice == \"2\":\n",
        "    chosen_lang = \"en\"\n",
        "else:\n",
        "    print(\"âŒ GeÃ§ersiz seÃ§im, varsayÄ±lan TÃ¼rkÃ§e seÃ§ildi.\")\n",
        "    chosen_lang = \"tr\"\n",
        "\n",
        "print(f\"ğŸ”¤ SeÃ§ilen dil: {chosen_lang}\")\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# âœ¨ Ã–zet OluÅŸturma (Gemini)\n",
        "# ============================================================\n",
        "model_name = \"gemini-2.0-flash\"\n",
        "model = genai.GenerativeModel(model_name, generation_config={\"temperature\": 0.3, \"max_output_tokens\": 1500})\n",
        "\n",
        "if chosen_lang == \"tr\":\n",
        "   prompt = f\"\"\"\n",
        "    AÅŸaÄŸÄ±daki akademik makalenin ayrÄ±ntÄ±lÄ± bir Ã¶zetini oluÅŸtur.\n",
        "    Ã‡alÄ±ÅŸmanÄ±n amacÄ±, kullanÄ±lan yÃ¶ntemler, veriler, bulgular ve sonuÃ§larÄ± aÃ§Ä±klayan\n",
        "    en az 6-8 cÃ¼mlelik akademik bir paragraf yaz.\n",
        "    AyrÄ±ca kullanÄ±lan modelleri veya algoritmalarÄ± da belirt.\n",
        "    TÃ¼rkÃ§e yaz.\n",
        "\n",
        "    Makale metni:\n",
        "    {text[:7000]}\n",
        "    \"\"\"\n",
        "else:\n",
        "   prompt = f\"\"\"\n",
        "    Provide a detailed summary of the following academic paper.\n",
        "    Include the research goal, methodology, data used, findings, and conclusions.\n",
        "    Write an academic-style paragraph with at least 6â€“8 sentences.\n",
        "    Also mention any models or algorithms used.\n",
        "    Write in English.\n",
        "\n",
        "    Paper text:\n",
        "    {text[:7000]}\n",
        "    \"\"\"\n",
        "\n",
        "print(\"\\nğŸ¤– Ã–zeti oluÅŸturuyor, lÃ¼tfen bekleyin...\")\n",
        "summary = model.generate_content(prompt)\n",
        "try:\n",
        "    summary = summary.text\n",
        "except:\n",
        "    summary = str(summary)\n",
        "\n",
        "print(\"\\nğŸ“„ Ã–ZET:\")\n",
        "print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "print(summary)\n",
        "print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§© ChromaDB + Soru Cevap\n",
        "# ============================================================\n",
        "print(\"\\nğŸ” Makale iÃ§eriÄŸi dizine ekleniyor...\")\n",
        "CHROMA_DIR = \"chroma_db\"\n",
        "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "embedding_model = \"models/embedding-001\"\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# HuggingFace Ã¼cretsiz embedding modeli\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = Chroma.from_texts(chunks, embeddings, persist_directory=CHROMA_DIR)\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_name,\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0.2,\n",
        "    system_prompt=\"You are an AI academic assistant. Only answer based on the provided paper content.\"\n",
        ")\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever())\n",
        "\n",
        "print(\"\\nğŸ’¬ ArtÄ±k makaleyle ilgili sorular sorabilirsiniz!\")\n",
        "print(\"Ã‡Ä±kmak iÃ§in 'q' yazÄ±n.\\n\")\n",
        "\n",
        "while True:\n",
        "    question = input(\"â“ Soru: \")\n",
        "    if question.lower() == \"q\":\n",
        "        print(\"ğŸ”š Sohbet sonlandÄ±rÄ±ldÄ±.\")\n",
        "        break\n",
        "    result = qa.invoke({\"question\": question, \"chat_history\": []})\n",
        "    print(\"\\nğŸ§  Cevap:\\n\", result[\"answer\"])\n",
        "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IJ639tFEhy1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}